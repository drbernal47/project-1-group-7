{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe the exploration and cleanup process  (using specifically the 2019 data to create our scatter plots and regressions)\n",
    "#Discuss insights you had while exploring the data that you didn't anticipate\n",
    "#Discuss any problems that arose after exploring the data, and how you resolved them\n",
    "#Present and discuss interesting figures developed during exploration, ideally with the help of Jupyter Notebook\n",
    "\n",
    "#To start, we narrowed down our choices in internet usage data to find a set that contained yearly breakdowns by country. \n",
    "#Then we picked one year to focus on \n",
    "\n",
    "\n",
    "#Path to happiness data\n",
    "\n",
    "#2015\n",
    "happiness2015= \"Resources/happiness2015.csv\"\n",
    "\n",
    "#2016\n",
    "happiness2016= \"Resources/happiness2016.csv\"\n",
    "\n",
    "#2017\n",
    "happiness2017 = \"Resources/happiness2017.csv\"\n",
    "\n",
    "#2018\n",
    "happiness2018 = \"Resources/happiness2018.csv\"\n",
    "\n",
    "#2019\n",
    "happiness2019 = \"Resources/happiness2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read happiness data\n",
    "\n",
    "#2015\n",
    "happiness15_df=pd.read_csv(happiness2015, encoding=\"ISO-8859-1\")\n",
    "\n",
    "#2016\n",
    "happiness16_df=pd.read_csv(happiness2016, encoding=\"ISO-8859-1\")\n",
    "\n",
    "#2017\n",
    "happiness17_df=pd.read_csv(happiness2017, encoding=\"ISO-8859-1\")\n",
    "\n",
    "#2018\n",
    "happiness18_df=pd.read_csv(happiness2018, encoding=\"ISO-8859-1\")\n",
    "\n",
    "#2019\n",
    "happiness19_df=pd.read_csv(happiness2019, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Hapiness data\n",
    "happiness15_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename country columns for merge, drop columns and rename columns to include year\n",
    "\n",
    "#2015 \n",
    "\n",
    " #add suffix _2015\n",
    "    \n",
    "happiness15_df2=happiness15_df.add_suffix('_2015')\n",
    "\n",
    "#country for merge\n",
    "\n",
    "rnhappiness15_df=happiness15_df2.rename(columns={'Country_2015': 'Country'})\n",
    "\n",
    "#Drop columns\n",
    "\n",
    "final15_df=rnhappiness15_df.drop([\"Standard Error_2015\", \"Region_2015\", \"Happiness Rank_2015\"], axis=1)\n",
    "\n",
    "#add suffixes to all then rename country to drop suffix\n",
    "\n",
    "\n",
    "#2016\n",
    "\n",
    "#add suffix _2016\n",
    "\n",
    "suffix16=happiness16_df.add_suffix('_2016')\n",
    "\n",
    "#Rename country for merge\n",
    "\n",
    "rnhappiness16_df=suffix16.rename(columns={'Country_2016' : 'Country'})\n",
    "\n",
    "#Drop columns\n",
    "\n",
    "final16_df=rnhappiness16_df.drop([\"Lower Confidence Interval_2016\", \"Upper Confidence Interval_2016\", \"Region_2016\", \"Happiness Rank_2016\"], axis=1)\n",
    "\n",
    "#2017\n",
    "\n",
    "#add suffix _2107\n",
    "\n",
    "suffix17=happiness17_df.add_suffix('_2017')\n",
    "\n",
    "#Rename for merge\n",
    "\n",
    "rnhappiness17_df=suffix17.rename(columns={'Country_2017' : 'Country'})\n",
    "\n",
    "#Drop Columns\n",
    "\n",
    "final17_df=rnhappiness17_df.drop([\"Whisker.high_2017\", \"Whisker.low_2017\", \"Happiness.Rank_2017\"], axis=1)\n",
    "\n",
    "#2018\n",
    "\n",
    "#add suffix _2018\n",
    "\n",
    "suffix18=happiness18_df.add_suffix('_2018')\n",
    "\n",
    "#Rename for merge\n",
    "\n",
    "rnhappiness18_df=suffix18.rename(columns={'Country or region_2018' : 'Country'})\n",
    "\n",
    "#Drop columns\n",
    "\n",
    "final18_df=rnhappiness18_df.drop(\"Overall rank_2018\", axis=1)\n",
    "\n",
    "#2019\n",
    "\n",
    "#add suffix _2019\n",
    "\n",
    "suffix19=happiness19_df.add_suffix('_2019')\n",
    "\n",
    "#rename for merge\n",
    "\n",
    "rnhappiness19_df=suffix19.rename(columns={'Country or region_2019' : 'Country'})\n",
    "\n",
    "#drop columns\n",
    "\n",
    "final19_df=rnhappiness19_df.drop(\"Overall rank_2019\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display to see if the rename worked\n",
    "\n",
    "final19_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge 2015 to 2016\n",
    "\n",
    "merged_happinessdf1=pd.merge(final15_df, final16_df, on=\"Country\")\n",
    "\n",
    "merged_happinessdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge 2017 to 15-16\n",
    "\n",
    "merged_happinessdf2=pd.merge(merged_happinessdf1, final17_df, on=\"Country\")\n",
    "\n",
    "merged_happinessdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge 2018 to 2015-2017\n",
    "merged_happinessdf3=pd.merge(merged_happinessdf2, final18_df, on=\"Country\")\n",
    "\n",
    "merged_happinessdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge 2019 to 15-18\n",
    "\n",
    "merged_happinessdf4=pd.merge(merged_happinessdf3, final19_df, on=\"Country\")\n",
    "\n",
    "merged_happinessdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to worldbank internet data\n",
    "wbinternet=\"Resources/worldbankinternet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read world bank internet data\n",
    "wbinternet_df=pd.read_csv(wbinternet, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropped unnamed columns\n",
    "wbinternet_df2=wbinternet_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\", \"Unnamed: 5\", \"Country Code\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displayed cleaned up worldbank data\n",
    "wbinternet_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename country column in worldbank data for merge\n",
    "\n",
    "rnwb_df=wbinternet_df2.rename(columns={'Country Name': 'Country',\n",
    "                                      '2015': 'Internet_2015',\n",
    "                                      '2016': 'Internet_2016',\n",
    "                                      '2017': 'Internet_2017',\n",
    "                                      '2018': 'Internet_2018',\n",
    "                                      '2019': 'Internet_2019'})\n",
    "\n",
    "\n",
    "rnwb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge happiness and internet data\n",
    "\n",
    "final_df=pd.merge(merged_happinessdf4, rnwb_df, on='Country')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the merged dataframe to a text file in order to read it in the Analysis notebook\n",
    "final_df.to_csv('merged.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   To start, we knew we were going to use the world happiness report data so we narrowed down our choices in internet usage \n",
    "data to find a set that contained yearly breakdowns by country to go along with the world happiness data. One thing we realized right away was that we would need a dataset with internet usage as a percentage of population as opposed to total population of users so that we would not just be analyzing which countries had the most people. Then we picked a year with the most recent data available in both sets to focus on for our graphs and analysis which was 2019. \n",
    "\n",
    "   We ran into a few issues when trying to get the data frames merged. Every year had its own csv and so its own data frame and we wanted to be able to look at individual years as well as having the option to look at changes over time for each country. Keeping the data clean and readable requiredsuffixes containing the year to be assigned to each data frame individually before merging all five years together and then finally merging it to the internet usage data. We ended up with some unnamed columns and one country with missing internet usage data that we needed to remove before we could do any calculations. Then we wrote the final merged data frame into a text file in order to open that file in another notebook for further analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
